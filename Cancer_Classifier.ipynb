{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e695e92-2d3f-4d6e-9224-e3c3c77b19ca",
   "metadata": {},
   "source": [
    "<!-- zelf ontwikkelen van neural net die uit text de types kanker kan classificeren doormiddel van NLP technieken\n",
    "\n",
    "probleem: specialisten in ziekenhuizen typen vaak een lang stuk tekst waar bepaalde personen dit niet lees baar voor is. \n",
    "oplossing: classificeren van text door te zien over welke type kanker een bepaald stuk tekst gaat. \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f0c4ab-cbdc-46d2-8ce7-7b9934109af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85041d0e-112a-4d8f-a81d-c2f579ce7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./MedicalReports.csv\")\n",
    "df = df.drop(['Unnamed: 0'], axis=1) # drop unwanted column unnamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3b69ed-e7f3-4b56-a87a-860380979d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Medical Reports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thyroid_Cancer</td>\n",
       "      <td>Thyroid surgery in  children in a single insti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thyroid_Cancer</td>\n",
       "      <td>\" The adopted strategy was the same as that us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thyroid_Cancer</td>\n",
       "      <td>coronary arterybypass grafting thrombosis ï¬b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thyroid_Cancer</td>\n",
       "      <td>Solitary plasmacytoma SP of the skull is an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thyroid_Cancer</td>\n",
       "      <td>This study aimed to investigate serum matrix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>Colon_Cancer</td>\n",
       "      <td>lipases are very versatile enzymes and produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>Colon_Cancer</td>\n",
       "      <td>recently extensive evidence has clarified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>Colon_Cancer</td>\n",
       "      <td>the introduction of combined conventional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>Colon_Cancer</td>\n",
       "      <td>dysregulation of lncrnas is frequent in gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>Colon_Cancer</td>\n",
       "      <td>endometrial cancer ec is a common malignan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Label                                    Medical Reports\n",
       "0     Thyroid_Cancer  Thyroid surgery in  children in a single insti...\n",
       "1     Thyroid_Cancer  \" The adopted strategy was the same as that us...\n",
       "2     Thyroid_Cancer  coronary arterybypass grafting thrombosis ï¬b...\n",
       "3     Thyroid_Cancer   Solitary plasmacytoma SP of the skull is an u...\n",
       "4     Thyroid_Cancer   This study aimed to investigate serum matrix ...\n",
       "...              ...                                                ...\n",
       "3370    Colon_Cancer   lipases are very versatile enzymes and produc...\n",
       "3371    Colon_Cancer      recently extensive evidence has clarified ...\n",
       "3372    Colon_Cancer      the introduction of combined conventional ...\n",
       "3373    Colon_Cancer      dysregulation of lncrnas is frequent in gl...\n",
       "3374    Colon_Cancer      endometrial cancer ec is a common malignan...\n",
       "\n",
       "[3375 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['Label', 'Medical Reports']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b188847-8c1d-4715-8470-e67e4f791af6",
   "metadata": {},
   "source": [
    "<h2>Datacleaning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2f6a1-656d-4854-b8dd-bac571cd0a1d",
   "metadata": {},
   "source": [
    "<!-- datacleaning -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2def2c-feef-4e7f-909b-967bd965509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "# Verwijderd interpunctie over alle medical reports teksten\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "    \n",
    "# Verwijderd interpunctie over alle medical reports teksten\n",
    "df['Medical Reports']= df['Medical Reports'].apply(lambda x:remove_punctuation(x))\n",
    "# maakt van alle hoofdletters kleine letters\n",
    "df['Medical Reports']= df['Medical Reports'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528f2193-fbb3-48ec-a9fa-3cb75ee02fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/minorai3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "nltk.download('stopwords') # helpt in verschillende talen stopwoorden te vinden\n",
    "\n",
    "stop_words = set(nltk_stopwords.words('english')) # gebruik stopwords in het engels\n",
    "\n",
    "# verwijder alle stopwoorden en zet deze woorden terug naar een lege \"\"\n",
    "df['Medical Reports'] = df['Medical Reports'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271ac7cc-4cd2-4e91-a26a-1555c1cc7154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Thyroid_Cancer    1405\n",
       "Colon_Cancer      1098\n",
       "Lung_Cancer        872\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()\n",
    "# \"check het aantal labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad8647-cbf7-4589-a250-40e428b07114",
   "metadata": {},
   "source": [
    "<h1>Prepair the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5782aa2-fc94-470a-9a1d-c54e10677413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 13:40:58.277568: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 13:40:59.266244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f154b5e-dab0-4924-9333-02b3f60f62b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get texts and labels\n",
    "texts = df['Medical Reports'].values\n",
    "labels = df['Label'].values\n",
    "\n",
    "# encode the labels \n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "encoded_labels\n",
    "# label 0 = Thyroid_Cancer    \n",
    "# label 1 = Colon_Cancer          \n",
    "# label 2 = Lung_Cancer            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e006c068-ad5e-4615-a715-4ac4f6203ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea21bfc2-9f97-4801-ba99-c3a3ffccdd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207764"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train) # Deze regel roept de fit_on_texts() methode van de tokenizer aan, waarbij de X_train dataset als invoer wordt gegeven. Deze methode traint de tokenizer om de unieke tokens in de dataset te identificeren en een numerieke waarde aan elk token toe te wijzen.\n",
    "vocab_size = len(tokenizer.word_index) + 1 # zoekt het aantal unique woorden dat door de tokenizer is geleerd. \n",
    "\n",
    "# tokenizer.word_index haalt de index van het woordenboek op en voegt er een aan toe met +1.\n",
    "# de extra 1 is voor het reserveren van het woord_id 0,1,2,3 etc. voor het padteken (padding)\n",
    "# Het padteken is een speciaal teken dat wordt gebruikt om tekst te vullen tot een bepaalde lengte. Het is gebruikelijk om het padteken te gebruiken in NLP-taken waarbij tekst wordt verwerkt door een neuraal netwerkmodel.\n",
    "\n",
    "# Door het padteken te reserveren voor het woord-ID 0, wordt ervoor gezorgd dat er altijd een woord-ID beschikbaar is voor het padteken. Dit is belangrijk omdat sommige neuraal netwerkmodellen het padteken vereisen als input.\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472768c4-6b9c-457c-af1a-25d4c81f51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text sequences to numerical sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "max_sequence_length = 100  # Adjust the value based on your data and sequence lengths\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = 3\n",
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes)\n",
    "y_test_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f557e1-bcbe-45d1-99fc-15c137195eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b79eff-e528-4c20-8420-dd96522c13fa",
   "metadata": {},
   "source": [
    "<p>\r\n",
    "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) that are well-suited for tasks that involve sequential data, such as natural language processing (NLP) tasks like text classification. Here's why LSTMs are particularly advantageous for classifying tokenized vectorized medical text:\r\n",
    "\r\n",
    "Capturing Long-Range Dependencies: LSTM networks are designed to address the vanishing gradient problem that plagues traditional RNNs. This problem arises when dealing with long sequences of data, as the gradients of the error function become increasingly small as they are backpropagated through the recurrent layers, making it difficult for the model to learn long-range dependencies between words in a sentence. LSTMs overcome this issue by using memory cells and gating mechanisms to selectively remember and update information over time, allowing them to capture long-range dependencies in the text.\r\n",
    "\r\n",
    "Handling Contextual Meaning: Medical text often contains complex medical terminology and subtle contextual nuances that are crucial for accurate classification. LSTMs excel at understanding the context in which words appear, allowing them to effectively interpret the meaning of medical jargon and identify patterns that indicate the correct classification.\r\n",
    "\r\n",
    "Processing Variable-Length Sequences: Medical reports and documents can vary significantly in length, posing a challenge for algorithms that require fixed-length inputs. LSTMs are able to handle variable-length sequences by processing the input text one token at a time, dynamically adjusting their internal state as they encounter new information.\r\n",
    "\r\n",
    "Adapting to Uncertainties: Medical text often contains ambiguities and uncertainties, making it challenging to classify with absolute certainty. LSTMs are adept at dealing with such uncertainties, as they can learn to probabilistically estimate the likelihood of different classifications based on the context of the text.\r\n",
    "\r\n",
    "In summary, LSTMs offer several advantages for classifying tokenized vectorized medical text:\r\n",
    "\r\n",
    "Ability to capture long-range dependencies in text\r\n",
    "\r\n",
    "Effective understanding of contextual meaning and medical terminology\r\n",
    "\r\n",
    "Handling of variable-length sequences\r\n",
    "\r\n",
    "Adaptation to uncertainties in medical text\r\n",
    "\r\n",
    "As a result, LSTMs have become a popular choice for a variety of medical NLP tasks, including disease classification, risk assessment, and patient outcome prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ad2105-b09b-4f93-a00a-eb938148a07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          20776400  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               117248    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20894035 (79.70 MB)\n",
      "Trainable params: 20894035 (79.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 13:41:08.385775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 13:41:08.386041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 13:41:08.467040: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c116871e-10b3-40de-b935-83e4718ce897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkp = ModelCheckpoint('best.h5', 'val_accuracy', mode='max', save_best_only=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1864122d-c7fb-4f02-b683-1a0c5f4df632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8090 - accuracy: 0.6415WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "85/85 [==============================] - 81s 871ms/step - loss: 0.8090 - accuracy: 0.6415\n",
      "Epoch 2/5\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9641WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "85/85 [==============================] - 72s 848ms/step - loss: 0.1087 - accuracy: 0.9641\n",
      "Epoch 3/5\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9804WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "85/85 [==============================] - 72s 853ms/step - loss: 0.0505 - accuracy: 0.9804\n",
      "Epoch 4/5\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9800WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "85/85 [==============================] - 73s 853ms/step - loss: 0.0431 - accuracy: 0.9800\n",
      "Epoch 5/5\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9770WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "85/85 [==============================] - 73s 859ms/step - loss: 0.0886 - accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc8c364a9d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32  \n",
    "epochs = 5  \n",
    "model.fit(X_train_padded, y_train_one_hot, batch_size=batch_size, epochs=epochs, callbacks=[checkp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51594bb2-be81-4cac-82e0-4b34a4c81550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 13ms/step - loss: 1.0993 - accuracy: 0.2993\n",
      "Test Loss: 1.0992774963378906\n",
      "Test Accuracy: 0.2992592453956604\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test_one_hot)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee882fa-8eb3-4d00-a3ae-e1c914b8c586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02671672,  0.01269192, -0.02109702,  0.0119508 , -0.03398069,\n",
       "       -0.01636165, -0.00141905,  0.01428673, -0.00179089, -0.04859804,\n",
       "       -0.02846521,  0.03496825, -0.03082448,  0.00908528, -0.04808161,\n",
       "        0.01286054, -0.0047849 , -0.01566142,  0.04292766,  0.04003518,\n",
       "        0.01633671, -0.04942472,  0.04724241, -0.03744145,  0.02398254,\n",
       "       -0.0036276 , -0.0156409 ,  0.03913525,  0.02579613, -0.03972366,\n",
       "        0.01206271,  0.03991858], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding\n",
    "\n",
    "# Deze regels definiëren de invoerlaag (inp) en de embeddingslaag (emb). De invoerlaag heeft een vorm van (250,), wat betekent dat het een sequentie van 250 tokens kan verwerken. De embeddingslaag neemt de invoersequentie en mapt elk token toe aan een vector van 32 dimensies, waardoor de tokens in wezen worden omgezet in numerieke representaties.\n",
    "inp = Input(shape=(250,)) \n",
    "emb = Embedding(100, 32)(inp)\n",
    "model2 = Model(inputs=inp, outputs=emb)\n",
    "model2 = Model(inputs=inp, outputs=emb)\n",
    "\n",
    "token_str = tokenizer.texts_to_sequences([\"surgycal\"])\n",
    "pad_str = pad_sequences(token_str, 250, padding = 'post')\n",
    "\n",
    "ret1 = model2.predict(pad_str.reshape(1,250))[0][0]\n",
    "ret1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c05802e-3b5e-40dd-822d-e3eaaeac616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "[ 0.0124376  -0.03279578 -0.00497026  0.02903298  0.04632712 -0.01467222\n",
      " -0.0422116  -0.04048993  0.01556461 -0.02149679  0.04977516  0.00035103\n",
      " -0.02256124  0.00210451  0.02124209 -0.04778255 -0.00391231  0.00391845\n",
      " -0.04109521 -0.02934302 -0.00417997 -0.02454194 -0.02103158 -0.0489982\n",
      " -0.03452469  0.01647905 -0.01217004  0.03209524 -0.03674219 -0.01855302\n",
      " -0.00137908  0.0389163 ]\n"
     ]
    }
   ],
   "source": [
    "token_str = tokenizer.texts_to_sequences([\"cancer\"])\n",
    "pad_str = pad_sequences(token_str, 250, padding = 'post')\n",
    "\n",
    "ret2 = model2.predict(pad_str.reshape(1,250))[0][0]\n",
    "print(ret2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b164a9c-7c7a-46d1-ade5-538f4bee47d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09589048]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(np.array(ret1).reshape(1,-1), np.array(ret2).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7a8da-0dd8-432a-b655-a4beef24b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3fead-ac20-461b-9560-1bdc0a93b31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590987f-cfdd-46ec-8d4c-f7ec005ee644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4233c1-2ec5-4891-a796-cccb500fb743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa89a3-0927-4931-98fb-9af2c2ca3cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be19d890-d083-419a-8f65-8320eb49d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_one_text(new_texts):\n",
    "    new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "    new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    predictions = model.predict(new_padded[0].reshape(1,100))\n",
    "    predicted_labels = label_encoder.inverse_transform([argmax(pred) for pred in predictions])\n",
    "    print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf97d0d9-cc17-4a1c-9a42-2eb4750bae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_multiple_texts(new_texts):\n",
    "    new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "    new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    predictions = model.predict(new_padded)\n",
    "    predicted_labels = label_encoder.inverse_transform([argmax(pred) for pred in predictions])\n",
    "    print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af8f5a4d-f3f3-4e96-9384-b23a5885d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "# Colon_Cancer \n",
    "\n",
    "# classify_multiple_texts(new_texts)\n",
    "# classify_one_text(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09ab8e0f-c1be-40e5-9845-6bf554cbb522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted Labels: ['Colon_Cancer']\n"
     ]
    }
   ],
   "source": [
    "new_text=['Cretinism is a severe form of iodine deficiency that affects the physical and mental development of children. Cretinism is characterized by stunted growth, intellectual disability, and neurological abnormalities. Iodine deficiency during pregnancy and early childhood can lead to cretinism, with the most severe cases occurring when iodine deficiency is present during fetal development.']\n",
    "\n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length, padding='post')\n",
    "predictions = model.predict(new_padded[0].reshape(1,100))\n",
    "\n",
    "predicted_labels = label_encoder.inverse_transform([argmax(pred) for pred in predictions])\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41207d1c-08b3-4214-9a26-c7627a3bc830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5977f58-b299-4461-913c-74ee7e0c9a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3oktPytorchEnv",
   "language": "python",
   "name": "3oktober"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
